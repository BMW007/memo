1、Softmax 函数的特点和作用是什么？
https://www.zhihu.com/question/23765351 写的不错。
softmax用于多分类过程中，它将多个神经元的输出，映射到（0,1）区间内，可以看成概率来理解，从而来进行多分类！

2、什么是CNN(卷积神经网络)？

卷积层负责提取特征，采样层负责特征选择，全连接层负责分类

为什么卷积神经网络更适合于图像分类？相比于传统的神经网络优势在哪里？
卷积层中的卷积过程是如何计算的？为什么卷积核是有效的？
卷积核的个数如何确定？应该选择多大的卷积核对于模型来说才是有效的？尺寸必须为正方形吗？如果是长方形因该怎么做？
步长的大小会对模型的效果产生什么样的影响？垂直方向和水平方向的步长是否得设定为相同的？
为什么要采用池化层，Max Pooling有什么好处？
Zero Padding有什么作用？如果已知一个feature map的尺寸，如何确定zero padding的数目？

3、什么是隐藏层？
神经网络中隐层有确切的含义吗？ 
https://www.zhihu.com/question/60493121 
一个神经网络包括有多个神经元“层”，输入层、隐藏层及输出层。
输入层负责接收输入及分发到隐藏层（因为用户看不见这些层，所以见做隐藏层）。
这些隐藏层负责所需的计算及输出结果给输出层，而用户则可以看到最终结果。

4、激活函数
sigmoid激活函数：除了输出层是一个二分类问题基本不会用它。
tanh激活函数：tanh是非常优秀的，几乎适合所有场合。
ReLu激活函数：最常用的默认函数，，如果不确定用哪个激活函数，就使用ReLu或者Leaky ReLu。

5、参数VS超参数（Parameters vs Hyperparameters）
比如算法中的learning rate a（学习率）、iterations(梯度下降法循环的数量)、L（隐藏层数目）、n^([l])（隐藏层单元数目）、
choice of activation function（激活函数的选择）都需要你来设置，这些数字实际上控制了最后的参数W和b的值，所以它们被称作超参数。

6.https://www.zhihu.com/question/268384579 
神经网络为什么可以（理论上）近似拟合任何函数？

7.CNN入门讲解：卷积层是如何提取特征的？
https://blog.csdn.net/bobo_jiang/article/details/79080561?utm_source=blogxgwz2

8.为什么要用神经网络？ https://ai.baidu.com/forum/topic/show/498386 

9.分类与回归区别是什么？ https://www.zhihu.com/question/21329754 
